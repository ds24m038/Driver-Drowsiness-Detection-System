{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# W&B Reporting - Understanding Experiment Results\n",
        "\n",
        "This notebook demonstrates how to access and interpret W&B experiment results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Login to W&B\n",
        "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Access W&B Project\n",
        "\n",
        "You can access your W&B project dashboard at:\n",
        "- **Project**: `SDC Project Final`\n",
        "- **URL**: https://wandb.ai/[your-entity]/SDC%20Project%20Final\n",
        "\n",
        "The dashboard shows:\n",
        "- Training metrics (loss, accuracy, precision, recall, F1)\n",
        "- Validation metrics\n",
        "- Test set performance\n",
        "- Model artifacts\n",
        "- Hyperparameters\n",
        "- Confusion matrices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Query Runs Programmatically\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize API\n",
        "api = wandb.Api()\n",
        "\n",
        "# Get project\n",
        "project = api.project(\"SDC Project Final\")\n",
        "print(f\"Project: {project.name}\")\n",
        "print(f\"Entity: {project.entity}\")\n",
        "\n",
        "# Get all runs\n",
        "runs = api.runs(f\"{project.entity}/{project.name}\")\n",
        "print(f\"\\nTotal runs: {len(runs)}\")\n",
        "\n",
        "# Display summary of runs\n",
        "for i, run in enumerate(runs[:5]):  # Show first 5 runs\n",
        "    print(f\"\\nRun {i+1}: {run.name}\")\n",
        "    print(f\"  Status: {run.state}\")\n",
        "    print(f\"  Best Val Accuracy: {run.summary.get('val_accuracy', 'N/A')}\")\n",
        "    print(f\"  Test Accuracy: {run.summary.get('test_accuracy', 'N/A')}\")\n",
        "    print(f\"  URL: {run.url}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download Model Artifacts\n",
        "\n",
        "You can download the best model from W&B artifacts:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Download model artifact from a specific run\n",
        "# Uncomment and modify as needed:\n",
        "# run = api.run(\"your-entity/SDC Project Final/your-run-id\")\n",
        "# artifact = run.use_artifact('best_model:latest')\n",
        "# artifact_dir = artifact.download()\n",
        "# print(f\"Model downloaded to: {artifact_dir}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
